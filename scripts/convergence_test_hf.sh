WANDB_ENTITY=kmfoda WANDB_PROJECT=lamb python3 /root/DTraining/scripts/run_mlm_no_trainer.py \
    --config_name google-bert/bert-large-uncased \
    --tokenizer_name google-bert/bert-large-uncased \
    --dataset_name kmfoda/bert_processed_dataset \
    --weight_decay 0.1 \
    --per_device_train_batch_size 64 \
    --gradient_accumulation_steps 500 \
    --learning_rate 0.000625 \
    --warmup_ratio 0.003125 \
    --max_seq_length 512 \
    --num_train_epochs 10 \
    --lr_scheduler_type linear \
    --preprocessing_num_workers 6 \
    --with_tracking \
    --report_to wandb